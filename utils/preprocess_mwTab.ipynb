{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e92066c2",
   "metadata": {},
   "source": [
    "# Preprocess mwTab Files from Metabolomics Workbench\n",
    "## Study ID: ST000385 and ST000386"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eecac13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Modules\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d91d047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert mwTab to TSV format\n",
    "def parse_mwTab(input_file, output_file):\n",
    "    sample_ids = []\n",
    "    classes = []\n",
    "    metabolite_names = []\n",
    "    feature_matrix = []\n",
    "    in_data_block = False\n",
    "\n",
    "    print(f\"Starting to parse '{input_file}'...\")\n",
    "\n",
    "    try:\n",
    "        with open(input_file, 'r') as f_in:\n",
    "            for line in f_in:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "\n",
    "                if line == 'MS_METABOLITE_DATA_START':\n",
    "                    in_data_block = True\n",
    "                    sample_line = next(f_in).strip()\n",
    "                    sample_ids = sample_line.split('\\t')[1:]\n",
    "                    factor_line = next(f_in).strip()\n",
    "                    factor_strings = factor_line.split('\\t')[1:]\n",
    "                    for f_str in factor_strings:\n",
    "                        cls = 'NA'\n",
    "                        parts = f_str.split('|')\n",
    "                        for part in parts:\n",
    "                            if 'Health State:' in part:\n",
    "                                cls = part.split(':', 1)[1].strip()\n",
    "                                break\n",
    "                        classes.append(cls)\n",
    "                    continue\n",
    "\n",
    "                if line == 'MS_METABOLITE_DATA_END':\n",
    "                    in_data_block = False\n",
    "                    break\n",
    "\n",
    "                if in_data_block:\n",
    "                    parts = line.split('\\t')\n",
    "                    metabolite_names.append(parts[0])\n",
    "                    feature_matrix.append(parts[1:])\n",
    "\n",
    "        transposed_features = list(zip(*feature_matrix))\n",
    "        print(f\"Parsed {len(sample_ids)} total samples and {len(metabolite_names)} features.\")\n",
    "\n",
    "        rows_written = 0\n",
    "        with open(output_file, 'w') as f_out:\n",
    "            header = ['SampleID', 'class'] + metabolite_names\n",
    "            f_out.write('\\t'.join(header) + '\\n')\n",
    "            for i in range(len(sample_ids)):\n",
    "                if classes[i] == 'NA':\n",
    "                    continue\n",
    "                row_data = [sample_ids[i], classes[i]] + list(transposed_features[i])\n",
    "                f_out.write('\\t'.join(row_data) + '\\n')\n",
    "                rows_written += 1\n",
    "\n",
    "        print(f\"\\nSuccessfully generated '{output_file}'.\")\n",
    "        print(f\"Total rows written: {rows_written} (Filtered out {len(sample_ids) - rows_written} 'NA' samples).\")\n",
    "        print(f\"Total columns: {len(header)}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{input_file}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Usage: parse_mwtab('ST000385_AN000620.txt', 'ST000385_processed.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3e91d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to incorporate 10% missing values\n",
    "def add_missing_values(df):\n",
    "    exclude_cols = ['SampleID', 'class']\n",
    "    cols = [c for c in df.columns if c not in exclude_cols]\n",
    "    mask = pd.DataFrame(np.random.rand(df.shape[0], len(cols)) < 0.1, columns=cols)\n",
    "    df[cols] = df[cols].mask(mask)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f4c6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Downsample a class\n",
    "def downsample(df, class_):\n",
    "    keep_fraction = 0.9\n",
    "    healthy_rows = df[df['class'] == class_].sample(frac=keep_fraction, random_state=42)\n",
    "    non_healthy_rows = df[df['class'] != class_]\n",
    "    df_subset = pd.concat([healthy_rows, non_healthy_rows], ignore_index=True)\n",
    "    return df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48eb80c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to parse 'ST000385_AN000620.txt'...\n",
      "Parsed 192 total samples and 152 features.\n",
      "\n",
      "Successfully generated 'ST000385_processed.tsv'.\n",
      "Total rows written: 172 (Filtered out 20 'NA' samples).\n",
      "Total columns: 154\n"
     ]
    }
   ],
   "source": [
    "# Preprocess ST000385 dataset\n",
    "parse_mwTab(\"ST000385_AN000620.txt\", \"ST000385_processed.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bb3acbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to parse 'ST000386_AN000621.txt'...\n",
      "Parsed 180 total samples and 181 features.\n",
      "\n",
      "Successfully generated 'ST000386_processed.tsv'.\n",
      "Total rows written: 162 (Filtered out 18 'NA' samples).\n",
      "Total columns: 183\n"
     ]
    }
   ],
   "source": [
    "# Preprocess ST000386 dataset\n",
    "parse_mwTab(\"ST000386_AN000621.txt\", \"ST000386_processed.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d954ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read processed datasets\n",
    "data1 = pd.read_csv(\"ST000385_processed.tsv\", sep=\"\\t\")\n",
    "data2 = pd.read_csv(\"ST000386_processed.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aeb5ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine dataset\n",
    "final_data = pd.concat([data1, data2], axis=0, join='inner')\n",
    "\n",
    "# Remove samples with Adenosquamous and Adenocarcnoma (very less samples)\n",
    "final_data = final_data[final_data[\"class\"].isin([\"Adenosquamous\", \"Adenocarcnoma\"])==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec7d9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing values \n",
    "final_data = add_missing_values(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23772829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform downsampling of Adenocarcinoma class\n",
    "final_data = downsample(final_data, class_=\"Healthy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c86cb008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write final data\n",
    "final_data = final_data.sample(frac=1).reset_index(drop=True)\n",
    "final_data.to_csv(\"metabolomics_data.csv\", quoting=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef97c019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307, 139)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final data shape\n",
    "final_data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
